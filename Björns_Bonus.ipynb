{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bj√∂rns Bonus.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO3VJxQQH2JSjdSHbT4IXmP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatManWalking/ml-lecture/blob/main/Bj%C3%B6rns_Bonus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI316RGyTNUi"
      },
      "source": [
        "pip install adversarial-robustness-toolbox --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbDP4HcVf0S"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFtW7N92TZHo"
      },
      "source": [
        "import art"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRfw8A8lTfIA",
        "outputId": "ef7d33c9-cac0-4c29-b2b6-ec4d4153cba6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from art.classifiers import PyTorchClassifier\n",
        "\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: The module art.classifiers will be removed in ART 1.8.0 and replaced with art.estimators.classification\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu8-SkdpTtP1"
      },
      "source": [
        "def initialize_model(model_name='vgg11', num_classes='10', feature_extract=True, use_pretrained=True):\n",
        "    \"\"\"\n",
        "    initalizes the version of VGG to be used and freezes the layers of the model and then add a new unfrozen head\n",
        "    \n",
        "    params:\n",
        "        model_name(str): for example vgg16_bn for VGG-net with 16 weight layers and batch normalization\n",
        "        num_classes(int): number of output classes (100 when using CIFAR100)\n",
        "        feature_extract(bool): should the layers be frozen or not\n",
        "        use_pretrained(bool): use the pretrained model weights or only the architecture itself\n",
        "    \"\"\"\n",
        "    \n",
        "    if model_name == 'vgg11':\n",
        "        model_ft = models.vgg11(pretrained=use_pretrained)\n",
        "    elif model_name == 'vgg11_bn':\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "    elif model_name == 'vgg16':\n",
        "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
        "    elif model_name == 'vgg16_bn':\n",
        "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
        "    elif model_name == 'vgg19':\n",
        "        model_ft = models.vgg19(pretrained=use_pretrained)\n",
        "    elif model_name == 'vgg19_bn':\n",
        "        model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
        "    \n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "    return model_ft, input_size"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSZc2AtqUzKq"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    \"\"\"\n",
        "    this freezes the layers in the network\n",
        "    the new layer added later will automatically be unfrozen\n",
        "    \"\"\"\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPImhjTU1Wb"
      },
      "source": [
        "def get_data_loader(batch_size=20):\n",
        "    \"\"\"\n",
        "    define data augmentation and return data loader with the cifar10 dataset loaded\n",
        "    parameters:\n",
        "        batch_size: size of the batch used for training and validation \n",
        "                    size of test batch is always 10\n",
        "    Return:\n",
        "        3 pytorch.dataloaders for easy batching of the dataset (train, validation and test)\n",
        "    \"\"\"\n",
        "\n",
        "    # data augmentation\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize([224,224]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
        "            transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
        "            #TODO if it is needed, add the random crop\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "        \n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "    test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=False, transform=transform)\n",
        "    \n",
        "    n = len(trainset)\n",
        "    train, val =torch.utils.data.random_split(trainset, \n",
        "                                                    [int(n//100*70), int(n//100*30)],\n",
        "                                                    generator=torch.Generator().manual_seed(42))\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=1000, shuffle=True, num_workers=0)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivfuzCoOU6JH",
        "outputId": "173fc5a4-d633-4e74-caa7-2044c1e12ac9"
      },
      "source": [
        "train_loader, val_loader, test_loader = get_data_loader(batch_size=20)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8aEy8hiU8oC"
      },
      "source": [
        "model_name = 'vgg11_bn'\n",
        "num_classes = 10\n",
        "feature_extract = True"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqoB0kwfU_rk"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HZY_unBVBrW"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIq5cbR5VDaz"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hgUqqvGVHV2"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sr7uSc1VJCP"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QznaTxNvVKde"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, model_name='vgg11', num_classes='10', feature_extract=True, use_pretrained=True):\n",
        "        \"\"\"\n",
        "        initalizes the version of VGG to be used and freezes the layers of the model and then add a new unfrozen head\n",
        "\n",
        "        params:\n",
        "            model_name(str): for example vgg16_bn for VGG-net with 16 weight layers and batch normalization\n",
        "            num_classes(int): number of output classes (100 when using CIFAR100)\n",
        "            feature_extract(bool): should the layers be frozen or not\n",
        "            use_pretrained(bool): use the pretrained model weights or only the architecture itself\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if model_name == 'vgg11':\n",
        "            model_ft = models.vgg11(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg11_bn':\n",
        "            model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg16':\n",
        "            model_ft = models.vgg16(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg16_bn':\n",
        "            model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg19':\n",
        "            model_ft = models.vgg19(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg19_bn':\n",
        "            model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model_ft = model_ft\n",
        "        \n",
        "        \n",
        "        self.set_parameter_requires_grad(feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "        self.model_ft.to(self.device)\n",
        "        self.feature_extract = feature_extract\n",
        "        self.input_size = input_size\n",
        "    \n",
        "    def get_params_to_update(self):\n",
        "        \"\"\" \n",
        "        prints the list of weights and bias that not frozen and will be tuned\n",
        "        \n",
        "        Gather the parameters to be optimized/updated in this run. If we are\n",
        "        finetuning we will be updating all parameters. However, if we are\n",
        "        doing feature extract method, we will only update the parameters\n",
        "        that we have just initialized, i.e. the parameters with requires_grad\n",
        "        is True.\n",
        "        \"\"\"\n",
        "\n",
        "        params_to_update = self.model_ft.parameters()\n",
        "        print(\"\\tWeights and Bias to be tuned:\")\n",
        "        if self.feature_extract:\n",
        "            params_to_update = []\n",
        "            for name,param in self.model_ft.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    params_to_update.append(param)\n",
        "                    print(\"\\t\\t\",name)\n",
        "        else:\n",
        "            for name,param in self.model_ft.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    print(\"\\t\\t\",name)\n",
        "                    \n",
        "        return params_to_update\n",
        "    \n",
        "    def set_parameter_requires_grad(self, feature_extracting):\n",
        "        \"\"\"\n",
        "        this freezes the layers in the network\n",
        "        the new layer added later will automatically be unfrozen\n",
        "        \"\"\"\n",
        "        if feature_extracting:\n",
        "            for param in self.model_ft.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "\n",
        "    def train_model(self, dataloader, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "        since = time.time()\n",
        "\n",
        "        val_acc_history = []\n",
        "        val_loss_history = []\n",
        "\n",
        "        best_model_wts = copy.deepcopy(self.model_ft.state_dict())\n",
        "        best_acc = 0.0\n",
        "        stop = False\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    self.model_ft.train()  # Set model to training mode\n",
        "                else:\n",
        "                    self.model_ft.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloader:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "                    \n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        # Get model outputs and calculate loss\n",
        "                        # Special case for inception because in training it has an auxiliary output. In train\n",
        "                        #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                        #   but in testing we only consider the final output.\n",
        "                        if is_inception and phase == 'train':\n",
        "                            # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                            outputs, aux_outputs = self.model_ft(inputs)\n",
        "                            loss1 = criterion(outputs, labels)\n",
        "                            loss2 = criterion(aux_outputs, labels)\n",
        "                            loss = loss1 + 0.4*loss2\n",
        "                        else:\n",
        "                            outputs = self.model_ft(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                epoch_loss = running_loss / len(dataloader.dataset)\n",
        "                epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(self.model_ft.state_dict())\n",
        "                if phase == 'val':\n",
        "                    val_acc_history.append(epoch_acc)\n",
        "                    # A simple addition to stop the training early\n",
        "                    val_loss_history.append(loss)\n",
        "                    if len(val_loss_history) > 3:\n",
        "                        stop = (abs(val_loss_history[-3] - val_loss_history[-3]) +\n",
        "                                abs(val_loss_history[-1] - val_loss_history[-2])) <= 0.001\n",
        "                        print(abs(val_loss_history[-3] - val_loss_history[-3]) +\n",
        "                                abs(val_loss_history[-1] - val_loss_history[-2]))\n",
        "                if stop:\n",
        "                    break\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "        # load best model weights\n",
        "        self.model_ft.load_state_dict(best_model_wts)\n",
        "        torch.save(self.model_ft, 'model.pth')\n",
        "        return self.model_ft, val_acc_history\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model_ft = torch.load(path)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgfScyy_wlk0"
      },
      "source": [
        "model_obj = Model(model_name=model_name, num_classes=num_classes, feature_extract=feature_extract, use_pretrained=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siRTFm6mxRWL",
        "outputId": "5df59a6e-b8a8-42fc-cb5e-8576f736e550"
      },
      "source": [
        "model_obj.model_ft"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoEJDgjxxVro",
        "outputId": "66d83696-dc5b-42c0-a548-9529a6d53c5d"
      },
      "source": [
        "# Now we finetune the model to get a descent classfication performance on it\n",
        "print(\"Original model training:\")\n",
        "params_to_update = model_obj.get_params_to_update()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original model training:\n",
            "\tWeights and Bias to be tuned:\n",
            "\t\t classifier.6.weight\n",
            "\t\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAoyqkq0yGa_"
      },
      "source": [
        "#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
        "num_epochs = 5"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT3Z1aOgVMSU"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp82V5cuyw1q"
      },
      "source": [
        "#model_ft, hist = model_obj.train_model(train_loader, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFelOwFxU2f"
      },
      "source": [
        "model_obj.load_model('model.pth')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUXq8-Dy37NO"
      },
      "source": [
        "model_ft = model_obj.model_ft"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-WaMUFtV6vH"
      },
      "source": [
        "sample = iter(test_loader)\n",
        "input_shape = next(sample)[0].shape"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzaLu-ZJV8m7"
      },
      "source": [
        "classifier_original = PyTorchClassifier(model_ft,\n",
        "                                        loss=nn.CrossEntropyLoss(),\n",
        "                                        input_shape=input_shape,\n",
        "                                        clip_values=(0, 1),\n",
        "                                        nb_classes=10)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MD2ebYJV-qL"
      },
      "source": [
        "len_steal = len(test_loader)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trUOBamVWCE6"
      },
      "source": [
        "# Stealing from the unprotected classifier.\n",
        "from art.attacks import ExtractionAttack\n",
        "from art.attacks.extraction import CopycatCNN, KnockoffNets\n",
        "\n",
        "attack_catalogue = {\"Probabilistic CopycatCNN\": CopycatCNN(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=True),\n",
        "                    \"Argmax CopycatCNN\": CopycatCNN(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=False),\n",
        "                    \"Probabilistic KnockoffNets\": KnockoffNets(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=True),\n",
        "                    \"Argmax KnockoffNets\": KnockoffNets(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=False),\n",
        "                   }"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Lt5Ap7WHKK"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXUYDyU7WEJ4",
        "outputId": "f299e9df-ff70-4f1d-8abf-4fd5b81870e8"
      },
      "source": [
        "results = []\n",
        "\n",
        "for test_set_x, test_set_y in test_loader:\n",
        "\n",
        "    for len_steal in [250, 1000, 3000, 5000]:\n",
        "        indices = np.random.permutation(len(test_set_x))\n",
        "        x_steal = test_set_x[indices[:len_steal]]\n",
        "        y_steal = test_set_y[indices[:len_steal]]\n",
        "        x_test = test_set_x[indices[len_steal:]]\n",
        "        y_test = test_set_y[indices[len_steal:]]\n",
        "\n",
        "        for name, attack in attack_catalogue.items():\n",
        "            \n",
        "            model_stolen = initialize_model(model_name=model_name,\n",
        "                                            num_classes=num_classes,\n",
        "                                            feature_extract=feature_extract,\n",
        "                                            use_pretrained=True)\n",
        "            print(model_stolen)\n",
        "            \n",
        "            classifier_stolen = PyTorchClassifier(model_stolen, loss=nn.CrossEntropyLoss(),\n",
        "                                                input_shape=input_shape, nb_classes=10,\n",
        "                                                clip_values=(0, 1))\n",
        "            \n",
        "            classifier_stolen = attack.extract(x_steal, y_steal, thieved_classifier=classifier_stolen)\n",
        "            acc = classifier_stolen._model.evaluate(x_test, y_test)[1]\n",
        "            print(name, \":\", acc)\n",
        "            results.append((name, len_steal, acc))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            "), 224)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-78b0d373d087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             classifier_stolen = PyTorchClassifier(model_stolen, loss=nn.CrossEntropyLoss(),\n\u001b[1;32m     21\u001b[0m                                                 \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                 clip_values=(0, 1))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mclassifier_stolen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_steal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_steal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthieved_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_stolen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, loss, input_shape, nb_classes, optimizer, use_amp, opt_level, loss_scale, channels_first, clip_values, preprocessing_defences, postprocessing_defences, preprocessing, device_type)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Get the internal layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layer_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layers\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mget_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The input model must inherit from `nn.Module`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m                         logger.info(\n\u001b[1;32m   1035\u001b[0m                             \u001b[0;34m\"Inferred %i hidden layers on PyTorch classifier.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The input model must inherit from `nn.Module`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H914CUfhcOcF"
      },
      "source": [
        "test_set[0][indices[:len_steal]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM2yLFhEcsyg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}