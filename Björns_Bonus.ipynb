{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Björns Bonus.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "300d2f3f02ff4f0ebfc8059fa3a9126e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a71188a65bb4f7e8d3fddf9af2d5a61",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a6a3fca634df4e7fb9c48c10633df841",
              "IPY_MODEL_37f6a358062a4d83b324aab3f13365de"
            ]
          }
        },
        "5a71188a65bb4f7e8d3fddf9af2d5a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6a3fca634df4e7fb9c48c10633df841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_41cf331eb29f47adb01d470013669a06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9b236a579904b168751bb8143d53bb8"
          }
        },
        "37f6a358062a4d83b324aab3f13365de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd615746775b40fa8e8d47b475890731",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:42&lt;00:00, 3989095.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5772f799fc7c409dae8bca50c8792360"
          }
        },
        "41cf331eb29f47adb01d470013669a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9b236a579904b168751bb8143d53bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd615746775b40fa8e8d47b475890731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5772f799fc7c409dae8bca50c8792360": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "501adcdcc2014d7db3fadbe148a76b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d91d3a5eeba47b6b528c348ac95411b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bba5f2864f944547bb2a46cfe8ed538c",
              "IPY_MODEL_88895b5f13fc4335be966f9359b677a2"
            ]
          }
        },
        "2d91d3a5eeba47b6b528c348ac95411b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bba5f2864f944547bb2a46cfe8ed538c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5efdc3b3df4465b8e4b479fd1a4ab7a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 531503671,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 531503671,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff7e819a7cc9420c98a75539124b61b3"
          }
        },
        "88895b5f13fc4335be966f9359b677a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fa0405234334380a10fcfecca2db91a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 507M/507M [00:03&lt;00:00, 140MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a71cfe231c94d4d9da055ac772c4937"
          }
        },
        "a5efdc3b3df4465b8e4b479fd1a4ab7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff7e819a7cc9420c98a75539124b61b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fa0405234334380a10fcfecca2db91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a71cfe231c94d4d9da055ac772c4937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatManWalking/ml-lecture/blob/main/Bj%C3%B6rns_Bonus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI316RGyTNUi"
      },
      "source": [
        "pip install adversarial-robustness-toolbox --quiet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbDP4HcVf0S",
        "outputId": "f9b98376-479a-4a95-f804-9d91a37f94cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFtW7N92TZHo"
      },
      "source": [
        "import art"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRfw8A8lTfIA"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from PIL import Image\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from art.classifiers import PyTorchClassifier\n",
        "\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOPImhjTU1Wb"
      },
      "source": [
        "def get_data_loader(batch_size=20):\n",
        "    \"\"\"\n",
        "    define data augmentation and return data loader with the cifar10 dataset loaded\n",
        "    parameters:\n",
        "        batch_size: size of the batch used for training and validation \n",
        "                    size of test batch is always 10\n",
        "    Return:\n",
        "        3 pytorch.dataloaders for easy batching of the dataset (train, validation and test)\n",
        "    \"\"\"\n",
        "\n",
        "    # data augmentation\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize([224,224]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
        "            transforms.RandomHorizontalFlip(), # Flip the data horizontally\n",
        "            #TODO if it is needed, add the random crop\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "        \n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "    test = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=False, transform=transform)\n",
        "    \n",
        "    n = len(trainset)\n",
        "    train, val =torch.utils.data.random_split(trainset, \n",
        "                                                    [int(n//100*70), int(n//100*30)],\n",
        "                                                    generator=torch.Generator().manual_seed(42))\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    val_loader = torch.utils.data.DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test, batch_size=1000, shuffle=True, num_workers=0)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "300d2f3f02ff4f0ebfc8059fa3a9126e",
            "5a71188a65bb4f7e8d3fddf9af2d5a61",
            "a6a3fca634df4e7fb9c48c10633df841",
            "37f6a358062a4d83b324aab3f13365de",
            "41cf331eb29f47adb01d470013669a06",
            "b9b236a579904b168751bb8143d53bb8",
            "bd615746775b40fa8e8d47b475890731",
            "5772f799fc7c409dae8bca50c8792360"
          ]
        },
        "id": "ivfuzCoOU6JH",
        "outputId": "2f35640e-bfe6-46be-e225-05b7da32db66"
      },
      "source": [
        "train_loader, val_loader, test_loader = get_data_loader(batch_size=20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "300d2f3f02ff4f0ebfc8059fa3a9126e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8aEy8hiU8oC"
      },
      "source": [
        "model_name = 'vgg11_bn'\n",
        "num_classes = 10\n",
        "feature_extract = True"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QznaTxNvVKde"
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, model_name='vgg11', num_classes='10', feature_extract=True, use_pretrained=True):\n",
        "        \"\"\"\n",
        "        initalizes the version of VGG to be used and freezes the layers of the model and then add a new unfrozen head\n",
        "\n",
        "        params:\n",
        "            model_name(str): for example vgg16_bn for VGG-net with 16 weight layers and batch normalization\n",
        "            num_classes(int): number of output classes (100 when using CIFAR100)\n",
        "            feature_extract(bool): should the layers be frozen or not\n",
        "            use_pretrained(bool): use the pretrained model weights or only the architecture itself\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if model_name == 'vgg11':\n",
        "            model = models.vgg11(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg11_bn':\n",
        "            model = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg16_bn':\n",
        "            model = models.vgg16_bn(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg19':\n",
        "            model = models.vgg19(pretrained=use_pretrained)\n",
        "        elif model_name == 'vgg19_bn':\n",
        "            model = models.vgg19_bn(pretrained=use_pretrained)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = model\n",
        "        \n",
        "        \n",
        "        self.set_parameter_requires_grad(feature_extract)\n",
        "        num_ftrs = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "        self.model.to(self.device)\n",
        "        self.feature_extract = feature_extract\n",
        "        self.input_size = input_size\n",
        "    \n",
        "    def get_params_to_update(self):\n",
        "        \"\"\" \n",
        "        prints the list of weights and bias that not frozen and will be tuned\n",
        "        \n",
        "        Gather the parameters to be optimized/updated in this run. If we are\n",
        "        finetuning we will be updating all parameters. However, if we are\n",
        "        doing feature extract method, we will only update the parameters\n",
        "        that we have just initialized, i.e. the parameters with requires_grad\n",
        "        is True.\n",
        "        \"\"\"\n",
        "\n",
        "        params_to_update = self.model.parameters()\n",
        "        print(\"\\tWeights and Bias to be tuned:\")\n",
        "        if self.feature_extract:\n",
        "            params_to_update = []\n",
        "            for name,param in self.model.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    params_to_update.append(param)\n",
        "                    print(\"\\t\\t\",name)\n",
        "        else:\n",
        "            for name,param in self.model.named_parameters():\n",
        "                if param.requires_grad == True:\n",
        "                    print(\"\\t\\t\",name)\n",
        "                    \n",
        "        return params_to_update\n",
        "    \n",
        "    def set_parameter_requires_grad(self, feature_extracting):\n",
        "        \"\"\"\n",
        "        this freezes the layers in the network\n",
        "        the new layer added later will automatically be unfrozen\n",
        "        \"\"\"\n",
        "        if feature_extracting:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "\n",
        "    def train_model(self, dataloader, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "        since = time.time()\n",
        "\n",
        "        val_acc_history = []\n",
        "        val_loss_history = []\n",
        "\n",
        "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "        best_acc = 0.0\n",
        "        stop = False\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    self.model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    self.model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloader:\n",
        "                    inputs = inputs.to(self.device)\n",
        "                    labels = labels.to(self.device)\n",
        "                    \n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        # Get model outputs and calculate loss\n",
        "                        # Special case for inception because in training it has an auxiliary output. In train\n",
        "                        #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                        #   but in testing we only consider the final output.\n",
        "                        if is_inception and phase == 'train':\n",
        "                            # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                            outputs, aux_outputs = self.model(inputs)\n",
        "                            loss1 = criterion(outputs, labels)\n",
        "                            loss2 = criterion(aux_outputs, labels)\n",
        "                            loss = loss1 + 0.4*loss2\n",
        "                        else:\n",
        "                            outputs = self.model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                epoch_loss = running_loss / len(dataloader.dataset)\n",
        "                epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
        "                if phase == 'val':\n",
        "                    val_acc_history.append(epoch_acc)\n",
        "                    # A simple addition to stop the training early\n",
        "                    val_loss_history.append(loss)\n",
        "                    if len(val_loss_history) > 3:\n",
        "                        stop = (abs(val_loss_history[-3] - val_loss_history[-3]) +\n",
        "                                abs(val_loss_history[-1] - val_loss_history[-2])) <= 0.001\n",
        "                        print(abs(val_loss_history[-3] - val_loss_history[-3]) +\n",
        "                                abs(val_loss_history[-1] - val_loss_history[-2]))\n",
        "                if stop:\n",
        "                    break\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "        # load best model weights\n",
        "        self.model.load_state_dict(best_model_wts)\n",
        "        torch.save(self.model, 'model.pth')\n",
        "        return self.model, val_acc_history\n",
        "\n",
        "    def forward():\n",
        "\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model = torch.load(path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgfScyy_wlk0",
        "outputId": "42228f9d-14a8-4400-b545-110b7ebb6222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "501adcdcc2014d7db3fadbe148a76b06",
            "2d91d3a5eeba47b6b528c348ac95411b",
            "bba5f2864f944547bb2a46cfe8ed538c",
            "88895b5f13fc4335be966f9359b677a2",
            "a5efdc3b3df4465b8e4b479fd1a4ab7a",
            "ff7e819a7cc9420c98a75539124b61b3",
            "0fa0405234334380a10fcfecca2db91a",
            "9a71cfe231c94d4d9da055ac772c4937"
          ]
        }
      },
      "source": [
        "model_obj = Model(model_name=model_name, num_classes=num_classes, feature_extract=feature_extract, use_pretrained=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "501adcdcc2014d7db3fadbe148a76b06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=531503671.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siRTFm6mxRWL",
        "outputId": "152970b2-a1ab-4b54-eca5-49097698af66"
      },
      "source": [
        "model_obj.model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoEJDgjxxVro",
        "outputId": "f3d2fd5f-ecc6-4f62-f114-807907b77653"
      },
      "source": [
        "# Now we finetune the model to get a descent classfication performance on it\n",
        "print(\"Original model training:\")\n",
        "params_to_update = model_obj.get_params_to_update()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original model training:\n",
            "\tWeights and Bias to be tuned:\n",
            "\t\t classifier.6.weight\n",
            "\t\t classifier.6.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAoyqkq0yGa_"
      },
      "source": [
        "#optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "optimizer_ft = optim.Adam(params_to_update, lr=0.001)\n",
        "num_epochs = 5"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT3Z1aOgVMSU"
      },
      "source": [
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp82V5cuyw1q"
      },
      "source": [
        "#model, hist = model_obj.train_model(train_loader, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBFelOwFxU2f"
      },
      "source": [
        "model_obj.load_model('/content/drive/MyDrive/DHBW Vorlesungen/6. Semester/Daten für Projekte/model.pth')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUXq8-Dy37NO"
      },
      "source": [
        "model = model_obj.model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-WaMUFtV6vH"
      },
      "source": [
        "sample = iter(test_loader)\n",
        "input_shape = next(sample)[0].shape"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzaLu-ZJV8m7"
      },
      "source": [
        "classifier_original = PyTorchClassifier(model,\n",
        "                                        loss=nn.CrossEntropyLoss(),\n",
        "                                        input_shape=input_shape,\n",
        "                                        clip_values=(0, 1),\n",
        "                                        nb_classes=10)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MD2ebYJV-qL"
      },
      "source": [
        "len_steal = len(test_loader)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trUOBamVWCE6"
      },
      "source": [
        "# Stealing from the unprotected classifier.\n",
        "from art.attacks import ExtractionAttack\n",
        "from art.attacks.extraction import CopycatCNN, KnockoffNets\n",
        "\n",
        "attack_catalogue = {\"Probabilistic CopycatCNN\": CopycatCNN(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=True),\n",
        "                    \"Argmax CopycatCNN\": CopycatCNN(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=False),\n",
        "                    \"Probabilistic KnockoffNets\": KnockoffNets(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=True),\n",
        "                    \"Argmax KnockoffNets\": KnockoffNets(classifier=classifier_original,\n",
        "                                              batch_size_fit=64,\n",
        "                                              batch_size_query=64,\n",
        "                                              nb_epochs=num_epochs,\n",
        "                                              nb_stolen=len_steal,\n",
        "                                              use_probability=False),\n",
        "                   }"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6Lt5Ap7WHKK"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bXUYDyU7WEJ4",
        "outputId": "dd2f5997-acd0-404c-fe86-e729d8bd59fa"
      },
      "source": [
        "results = []\n",
        "\n",
        "for test_set_x, test_set_y in test_loader:\n",
        "\n",
        "    for len_steal in [250, 1000, 3000, 5000]:\n",
        "        indices = np.random.permutation(len(test_set_x))\n",
        "        x_steal = test_set_x[indices[:len_steal]]\n",
        "        y_steal = test_set_y[indices[:len_steal]]\n",
        "        x_test = test_set_x[indices[len_steal:]]\n",
        "        y_test = test_set_y[indices[len_steal:]]\n",
        "\n",
        "        for name, attack in attack_catalogue.items():\n",
        "            \n",
        "            model_stolen = Model(model_name=model_name,\n",
        "                                            num_classes=num_classes,\n",
        "                                            feature_extract=feature_extract,\n",
        "                                            use_pretrained=True)\n",
        "            \n",
        "            params_to_update = model_obj.get_params_to_update()\n",
        "            optimizer_ft = optim.Adam(model_stolen.parameters(), lr=0.001)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            #print(model_stolen)\n",
        "            \n",
        "            classifier_stolen = PyTorchClassifier(model_stolen, loss=criterion, optimizer=optimizer_ft,\n",
        "                                                input_shape=input_shape, nb_classes=10,\n",
        "                                                clip_values=(0, 1))\n",
        "            \n",
        "            classifier_stolen = attack.extract(x_steal, y_steal, thieved_classifier=classifier_stolen)\n",
        "            acc = classifier_stolen._model.evaluate(x_test, y_test)[1]\n",
        "            print(name, \":\", acc)\n",
        "            results.append((name, len_steal, acc))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tWeights and Bias to be tuned:\n",
            "\t\t classifier.6.weight\n",
            "\t\t classifier.6.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-db6651ee8bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                 clip_values=(0, 1))\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mclassifier_stolen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_steal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_steal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthieved_classifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier_stolen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_stolen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/attacks/attack.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/attacks/extraction/copycat_cnn.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfake_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;31m# Perform prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# Form the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H914CUfhcOcF"
      },
      "source": [
        "test_set[0][indices[:len_steal]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM2yLFhEcsyg",
        "outputId": "4f96dcf5-b8f4-40c4-c589-8253d3c92552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model_stolen(test_set_x[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-afcae6fdc92b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_stolen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mregistered\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatter\u001b[0m \u001b[0msilently\u001b[0m \u001b[0mignores\u001b[0m \u001b[0mthem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \"\"\"\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHEVkL1we9Kw",
        "outputId": "e8b01642-0dc6-4b24-cd8d-7200be24952e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "model_obj.model(test_set_x[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9ba3ffee8df0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1131\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR6YSjWGgWiv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}